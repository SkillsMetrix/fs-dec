package csv;

import java.io.BufferedReader;
import java.io.FileReader;
import java.io.IOException;
import java.util.Properties;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;

public class PaymentProducer {
	public static void main(String[] args) throws InterruptedException, IOException {
		String bootstrap = "localhost:9092";
        String topic = "payment-topic";

        Properties props = new Properties();
        
        props.put("bootstrap.servers", bootstrap);
        props.put("key.serializer",
                  "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer",
                  "org.apache.kafka.common.serialization.StringSerializer");

        
        KafkaProducer<String, String> p= new KafkaProducer<String, String>(props);
        
        String csvFile="C:/data/payments.csv";
        
        BufferedReader br= new BufferedReader(new FileReader(csvFile));
        String line;
        br.readLine();
        while((line= br.readLine()) !=null) {
        	p.send(new ProducerRecord<>("payments-input",null,line));
        	System.out.println("Sent "+line);
        }
      
      
        p.close();
        System.out.println("Producer Done its Job....!");
       
   
	}

}



-----------

package csv;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.errors.WakeupException;
 
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;

public class AggregatesConsumer {
    private static final ObjectMapper mapper = new ObjectMapper();

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers","localhost:9092");
        props.put("group.id","csv-reader");
        props.put("key.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
        props.put("auto.offset.reset","earliest");
        
        KafkaConsumer<String,String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("payments-aggregates"));
        
        System.out.println("AggregatesConsumer started...");
      
            while (true) {
                ConsumerRecords<String,String> records = consumer.poll(Duration.ofMillis(500));
                for(ConsumerRecord<String, String> r: records) {
                	String[] agg= r.value().split(",");
                	 System.out.printf("%s : count=%s total=%s%n",
                             r.key(),
                            agg[0],
                            agg[1]);
                }
                
             
            }}
}
    -----


package csv;

import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.*;
import org.apache.kafka.streams.kstream.*;

import java.util.Properties;

public class PaymentStreamsCSV {

    public static void main(String[] args) {

        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "payments-csv-app");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());

        StreamsBuilder builder = new StreamsBuilder();

        // CSV: id,method,amount  (coming as plain string)
        KStream<String, String> src = builder.stream("payments-input");

        // Key by payment method (column 2)
        KStream<String, String> keyed = src.flatMap((k, v) -> {
            try {
                String[] parts = v.split(",");
                if (parts.length < 3) return java.util.List.of();
                String method = parts[1].toUpperCase(); // UPI/CARD/CASH
                return java.util.List.of(KeyValue.pair(method, v));
            } catch (Exception e) {
                return java.util.List.of();
            }
        });

        // Minimal aggregation: count + sum(amount)
        KTable<String, String> agg = keyed
            .groupByKey()
            .aggregate(
                () -> "0,0.0",    // initial value: "count,totalAmount"
                (method, newVal, aggVal) -> {
                    try {
                        String[] parts = newVal.split(",");
                        double amount = Double.parseDouble(parts[2]); // CSV amount

                        String[] aggParts = aggVal.split(",");
                        long count = Long.parseLong(aggParts[0]);
                        double total = Double.parseDouble(aggParts[1]);

                        count += 1;
                        total += amount;

                        return count + "," + total;
                    } catch (Exception e) {
                        return aggVal;
                    }
                },
                Materialized.with(Serdes.String(), Serdes.String())
            );

        // Write aggregates: key=method value="count,totalAmount"
        agg.toStream().to("payments-aggregates", Produced.with(Serdes.String(), Serdes.String()));

        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();
        System.out.println("CSV Streams App started.");
    }
}

